{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a3753c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\tkaan\\anaconda3\\envs\\tensofrlow_py39\\lib\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\tkaan\\anaconda3\\envs\\tensofrlow_py39\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.3 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.1/9.3 MB 1.3 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.2/9.3 MB 1.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/9.3 MB 2.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.3 MB 2.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.8/9.3 MB 2.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.9/9.3 MB 2.8 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 2.8 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.2/9.3 MB 2.9 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.3/9.3 MB 2.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.5/9.3 MB 2.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/9.3 MB 2.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.7/9.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.9/9.3 MB 2.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.0/9.3 MB 2.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.2/9.3 MB 2.9 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.3/9.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.4/9.3 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.6/9.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.7/9.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.9/9.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.0/9.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.2/9.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.5/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.6/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.7/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.0/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.2/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.3/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.5/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.6/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.7/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.9/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.0/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.1/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.3/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.4/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.6/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.7/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.9/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.0/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.1/9.3 MB 3.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.3/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.5/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.6/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.7/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.9/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.0/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.2/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.3/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.5/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.6/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.8/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.9/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.0/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.3/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.6/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.3/9.3 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 266.2/302.2 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.2/302.2 kB 6.2 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2686ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "#buradaki dense:  \"Fully Connected\" veya \"Dense\" katmanını temsil eder.  yani; Bu katman, önceki katmandaki tüm birimlerin\n",
    "#birbirine bağlı olduğu ve her bir birimin, bir sonraki katmandaki tüm birimlerle bağlantılı olduğu bir yapıya sahiptir. \n",
    "#Bu katman, girdi verilerini alır ve ağırlık matrisiyle çarparak çıktıyı üretir. \n",
    "#Ardından, genellikle bir aktivasyon fonksiyonuyla çıktı işlenir.\n",
    "\n",
    "#dropout ise: seyreltme islemini temsil eder,\n",
    "\n",
    "#flatten ise: duzlestirme islemi.\n",
    "\n",
    "#conv2d ise: evrisim agimiz.\n",
    "\n",
    "#MaxPooling2D ise: piksel ekleme kavramimizdir.\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7be9976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkaan\\anaconda3\\envs\\tensofrlow_py39\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "2/2 [==============================] - 2s 402ms/step - loss: 7.8783 - accuracy: 0.4444\n",
      "Epoch 2/35\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 5.3592 - accuracy: 0.4127\n",
      "Epoch 3/35\n",
      "2/2 [==============================] - 1s 333ms/step - loss: 3.9653 - accuracy: 0.3095\n",
      "Epoch 4/35\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 1.1357 - accuracy: 0.5159\n",
      "Epoch 5/35\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.1465 - accuracy: 0.5397\n",
      "Epoch 6/35\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.9513 - accuracy: 0.5556\n",
      "Epoch 7/35\n",
      "2/2 [==============================] - 1s 351ms/step - loss: 0.8306 - accuracy: 0.7063\n",
      "Epoch 8/35\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 0.7560 - accuracy: 0.7143\n",
      "Epoch 9/35\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.6507 - accuracy: 0.6667\n",
      "Epoch 10/35\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.4739 - accuracy: 0.8889\n",
      "Epoch 11/35\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 0.4231 - accuracy: 0.8651\n",
      "Epoch 12/35\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.3575 - accuracy: 0.9365\n",
      "Epoch 13/35\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.2513 - accuracy: 0.9524\n",
      "Epoch 14/35\n",
      "2/2 [==============================] - 1s 357ms/step - loss: 0.2447 - accuracy: 0.9444\n",
      "Epoch 15/35\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.2157 - accuracy: 0.9286\n",
      "Epoch 16/35\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 0.1898 - accuracy: 0.9524\n",
      "Epoch 17/35\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 0.1860 - accuracy: 0.9444\n",
      "Epoch 18/35\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 0.1429 - accuracy: 0.9603\n",
      "Epoch 19/35\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.1239 - accuracy: 0.9683\n",
      "Epoch 20/35\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.1166 - accuracy: 0.9762\n",
      "Epoch 21/35\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.1226 - accuracy: 0.9603\n",
      "Epoch 22/35\n",
      "2/2 [==============================] - 1s 271ms/step - loss: 0.1008 - accuracy: 0.9683\n",
      "Epoch 23/35\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0822 - accuracy: 0.9841\n",
      "Epoch 24/35\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0894 - accuracy: 0.9683\n",
      "Epoch 25/35\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0723 - accuracy: 0.9762\n",
      "Epoch 26/35\n",
      "2/2 [==============================] - 1s 335ms/step - loss: 0.0664 - accuracy: 0.9762\n",
      "Epoch 27/35\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0497 - accuracy: 0.9841\n",
      "Epoch 28/35\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.0425 - accuracy: 0.9921\n",
      "Epoch 29/35\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0417 - accuracy: 0.9921\n",
      "Epoch 30/35\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 31/35\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 32/35\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 33/35\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 34/35\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 35/35\n",
      "2/2 [==============================] - 1s 278ms/step - loss: 0.0376 - accuracy: 0.9921\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0194 - accuracy: 0.9921\n",
      "Eğitim doğruluğu: % 99.20634627342224\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0410 - accuracy: 1.0000\n",
      "Test doğruluğu: % 100.0\n"
     ]
    }
   ],
   "source": [
    "imgs = glob.glob(\"./img_nihai/*.png\")\n",
    "\n",
    "width = 125\n",
    "height = 50\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "#egitim oncesi bazi donusumler uyguliycaz resimlere,\n",
    "for img in imgs:\n",
    "    \n",
    "    filename = os.path.basename(img)\n",
    "    #burada _ ile split ettik ve 0. inseksi aldik bunun sebebi ise bizim resimlerimizin ilk basinda hangi hareket olduug yaziyor\n",
    "    label = filename.split(\"_\")[0]\n",
    "    #simdi ise resmimizi convert ediyoruz yani size ini degistiriyoruz.\n",
    "    im = np.array(Image.open(img).convert(\"L\").resize((width, height)))\n",
    "    im = im / 255\n",
    "    X.append(im)\n",
    "    Y.append(label)\n",
    "    \n",
    "X = np.array(X)\n",
    "X = X.reshape(X.shape[0], width, height, 1)\n",
    "\n",
    "\n",
    "#burada y nin icine yani down up ve right a one hot encode ve label encode islemini yapiyoruz.\n",
    "#yani ilk once up down ve right i sayiya ceviriyoruz mesela 0 1 ve 2 olark sonrasinda one hot encoder yapiyopruz o da\n",
    "#0 icin 100 1 icin 010 2 icin 001 seklinde sayilari birbirinden ayirt etmesini saglayan bir yontem.\n",
    "def onehot_labels(values):\n",
    "    label_encoder = LabelEncoder()\n",
    "    #buradaki fit aslinda ne yapacagini ogreniyor gibi dusunebiliriz sonrasinda transform ediyor yani donusturuyor.\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    onehot_encoder = OneHotEncoder(sparse = False)\n",
    "    #buranin sonunda 1 koyduk cunku integer_ encodede baktigimizda 169 gozukuyor sdece onu 1 yapmaliyiz ki hata almayalim.\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded\n",
    "\n",
    "Y = onehot_labels(Y)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, Y , test_size = 0.25, random_state = 2)\n",
    "\n",
    "\n",
    "\n",
    "#cnn modelimizi insa ediyoruz.\n",
    "#burasi layerlarimiizi uzerine ekleyecegimiz temel yapi.\n",
    "model = Sequential()\n",
    "\n",
    "#ilk once conv2d ekliyoruz, 32 tane filtre kullaniyoruz ksize yani filtre boyutrumuz 3 e 3 oluyor.\n",
    "#activation fonksiyonu olarak da relu kullaniyoruz, girdi boyutlarimizi ise yukarda belirttigimiz w h ve 1 olarak belirliyoruz.\n",
    "model.add(Conv2D(32, kernel_size = (3,3), activation = \"relu\", input_shape = (width, height, 1)))\n",
    "\n",
    "#bir tane daha conv layer ekliyoruz, bundan istedigimiz kadar ekleyuebiliriz ve istedigimiz kadar karmasiklastirabiliriz.\n",
    "#bir oncekinin ciktigi buranin girdisi olacagi icin tekrardan boyutlari falan belirtmemize gerek yok.\n",
    "#burda karmasikligi artirdik 64 yaptik.\n",
    "model.add(Conv2D(64, kernel_size = (3,3), activation = \"relu\"))\n",
    "\n",
    "#simdi ise pooling yani piksek eklemeyi yapiyoruz.\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#simdi ise seyreltme ekliyoruz.\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#soimdi ise duzlestirme islemi yapiyopruz.\n",
    "model.add(Flatten())\n",
    "\n",
    "#burada ise siniflandirma islemini gerceklestiriyoruz. burad 128 tane noron yapiyoruz, aktivasyon ise relu yapiyoruz.\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "#burasi ise bizim cikti layerimiz. softmax yapiyoruz. softmax fonksiyonunu 2 den fazla cikti varsa kullaniyoruz.\n",
    "model.add(Dense(3, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "# if os.path.exists(\"./trex_weight.h5\"):\n",
    "#     model.load_weights(\"trex_weight.h5\")\n",
    "#     print(\"Weights yuklendi\")    \n",
    "\n",
    "\n",
    "\n",
    "#burda ise modelimizin compile etmek icin gerekli kodlarimizi yaziyoruz.\n",
    "#loss fonksiyonu bizim en son niahi olarak hatalarimizi hesaplamamizi saglayan fonksiyon. peki bu ne ise yariyor;\n",
    "#baslangicta hatamiz yani kayiplarimiz cok yuksek cikiyor ve bu kaybimiza gore parametrelerimizi guncelliyoruz,\n",
    "#geriye dogru turev alma islemi yapiyoruz ve sonucunda da bizim degisimimizi buluyoruz ve bu degisime gore paramtrelerimizi\n",
    "#guncelliyoruz. bu turev alma islemini de ortaya cikan loss degerimize gore yapiyoruz.\n",
    "#eger loss cok azsa bu bizim modelimizin iyi egitildigi anlamina geliyor.\n",
    "\n",
    "#optimizer ise bizim parametrelerimizi optimize ediyor burda gradient descent algoritmasi kullaniliyor.\n",
    "\n",
    "#metrics ise bizim modelimizin sonuclarinizi yorumlamamiz icin gerekli olan yapidir. bize yuzde olarak basariyi soyler.\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"Adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "#artik training islemine geldik. train x bizim resimleri iceren yapi train y ise bunlarin etiketlerini iceren yapi. \n",
    "#epochs ise bizim resimlerimizin toplamda kac kez egitilecegi anlamina geliyor. 35 kere egitim iterasyon gerceklessin diyoruz.\n",
    "#batch size ise bizim resimlerimizin kac grup halinde itreasyona sokulacagini soyluyoruz.\n",
    "#yani ilk 64 sonra 64 sonra 64 sonra geri kalanlari egitime sokuyoruz. bu total islem ise bir tane epochs anlamina gelmektedir.\n",
    "#bunu epochs sayisi kadar tekrarliyor.\n",
    "model.fit(train_X, train_y, epochs = 35, batch_size = 64)\n",
    "\n",
    "#sonuc olarak ortaya score train degerimiz cikacak. score un 0. indeksi bize kaybi 1. indeksi ise bize accuracy i dondurur.\n",
    "#bunu 100 ile carpinca bize egitim dogrulugunun yuzdesini vericektir.\n",
    "score_train = model.evaluate(train_X, train_y)\n",
    "print(\"Eğitim doğruluğu: %\",score_train[1]*100)    \n",
    "\n",
    "#aynisini burda test dogrulugu icin de yapiyoruz.\n",
    "score_test = model.evaluate(test_X, test_y)\n",
    "print(\"Test doğruluğu: %\",score_test[1]*100)      \n",
    "    \n",
    " \n",
    "open(\"model_new.json\",\"w\").write(model.to_json())\n",
    "model.save_weights(\"trex_weight_new.h5\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738241c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7aad22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ad8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbad61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f6a964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93867219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80517c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fdbf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2268b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ab14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0f113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc799c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b296c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca604cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366cb0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2c5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddbaa42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
